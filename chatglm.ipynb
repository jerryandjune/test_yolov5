{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb2b496-4087-4462-bccc-3113b075abb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Requirement already satisfied: protobuf in ./miniconda3/lib/python3.10/site-packages (from -r /root/ChatGLM2-6B-main/requirements.txt (line 1)) (4.25.3)\n",
      "Collecting transformers==4.30.2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/5b/0b/e45d26ccd28568013523e04f325432ea88a442b4e3020b757cf4361f0120/transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "Requirement already satisfied: cpm_kernels in ./miniconda3/lib/python3.10/site-packages (from -r /root/ChatGLM2-6B-main/requirements.txt (line 3)) (1.0.11)\n",
      "Requirement already satisfied: torch>=2.0 in ./miniconda3/lib/python3.10/site-packages (from -r /root/ChatGLM2-6B-main/requirements.txt (line 4)) (2.1.2+cu118)\n",
      "Requirement already satisfied: gradio in ./miniconda3/lib/python3.10/site-packages (from -r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (4.40.0)\n",
      "Requirement already satisfied: mdtex2html in ./miniconda3/lib/python3.10/site-packages (from -r /root/ChatGLM2-6B-main/requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: sentencepiece in ./miniconda3/lib/python3.10/site-packages (from -r /root/ChatGLM2-6B-main/requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: accelerate in ./miniconda3/lib/python3.10/site-packages (from -r /root/ChatGLM2-6B-main/requirements.txt (line 8)) (0.33.0)\n",
      "Requirement already satisfied: sse-starlette in ./miniconda3/lib/python3.10/site-packages (from -r /root/ChatGLM2-6B-main/requirements.txt (line 9)) (2.1.3)\n",
      "Requirement already satisfied: streamlit>=1.24.0 in ./miniconda3/lib/python3.10/site-packages (from -r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (1.37.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./miniconda3/lib/python3.10/site-packages (from transformers==4.30.2->-r /root/ChatGLM2-6B-main/requirements.txt (line 2)) (2024.7.24)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./miniconda3/lib/python3.10/site-packages (from transformers==4.30.2->-r /root/ChatGLM2-6B-main/requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: requests in ./miniconda3/lib/python3.10/site-packages (from transformers==4.30.2->-r /root/ChatGLM2-6B-main/requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.10/site-packages (from transformers==4.30.2->-r /root/ChatGLM2-6B-main/requirements.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./miniconda3/lib/python3.10/site-packages (from transformers==4.30.2->-r /root/ChatGLM2-6B-main/requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in ./miniconda3/lib/python3.10/site-packages (from transformers==4.30.2->-r /root/ChatGLM2-6B-main/requirements.txt (line 2)) (0.24.5)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./miniconda3/lib/python3.10/site-packages (from transformers==4.30.2->-r /root/ChatGLM2-6B-main/requirements.txt (line 2)) (0.4.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./miniconda3/lib/python3.10/site-packages (from transformers==4.30.2->-r /root/ChatGLM2-6B-main/requirements.txt (line 2)) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./miniconda3/lib/python3.10/site-packages (from transformers==4.30.2->-r /root/ChatGLM2-6B-main/requirements.txt (line 2)) (4.66.4)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.10/site-packages (from transformers==4.30.2->-r /root/ChatGLM2-6B-main/requirements.txt (line 2)) (3.14.0)\n",
      "Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 4)) (3.1.4)\n",
      "Requirement already satisfied: typing-extensions in ./miniconda3/lib/python3.10/site-packages (from torch>=2.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 4)) (4.12.2)\n",
      "Requirement already satisfied: triton==2.1.0 in ./miniconda3/lib/python3.10/site-packages (from torch>=2.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: fsspec in ./miniconda3/lib/python3.10/site-packages (from torch>=2.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 4)) (2024.5.0)\n",
      "Requirement already satisfied: sympy in ./miniconda3/lib/python3.10/site-packages (from torch>=2.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 4)) (1.12.1)\n",
      "Requirement already satisfied: networkx in ./miniconda3/lib/python3.10/site-packages (from torch>=2.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: orjson~=3.0 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (3.10.6)\n",
      "Requirement already satisfied: markupsafe~=2.0 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (2.1.5)\n",
      "Requirement already satisfied: pydub in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.25.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (2.10.0)\n",
      "Requirement already satisfied: urllib3~=2.0 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (2.2.2)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.0.9)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.12.3)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (23.2.1)\n",
      "Requirement already satisfied: gradio-client==1.2.0 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: fastapi in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.111.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (4.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.27.0)\n",
      "Requirement already satisfied: ffmpy in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.12.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (2.2.2)\n",
      "Requirement already satisfied: matplotlib~=3.0 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (3.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.30.4)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (10.3.0)\n",
      "Requirement already satisfied: ruff>=0.2.2 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.5.5)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in ./miniconda3/lib/python3.10/site-packages (from gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (6.4.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in ./miniconda3/lib/python3.10/site-packages (from gradio-client==1.2.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (12.0)\n",
      "Requirement already satisfied: latex2mathml in ./miniconda3/lib/python3.10/site-packages (from mdtex2html->-r /root/ChatGLM2-6B-main/requirements.txt (line 6)) (3.77.0)\n",
      "Requirement already satisfied: markdown in ./miniconda3/lib/python3.10/site-packages (from mdtex2html->-r /root/ChatGLM2-6B-main/requirements.txt (line 6)) (3.6)\n",
      "Requirement already satisfied: psutil in ./miniconda3/lib/python3.10/site-packages (from accelerate->-r /root/ChatGLM2-6B-main/requirements.txt (line 8)) (5.9.8)\n",
      "Requirement already satisfied: starlette in ./miniconda3/lib/python3.10/site-packages (from sse-starlette->-r /root/ChatGLM2-6B-main/requirements.txt (line 9)) (0.37.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in ./miniconda3/lib/python3.10/site-packages (from streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (5.3.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in ./miniconda3/lib/python3.10/site-packages (from streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (17.0.0)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in ./miniconda3/lib/python3.10/site-packages (from streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (8.5.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in ./miniconda3/lib/python3.10/site-packages (from streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (5.4.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in ./miniconda3/lib/python3.10/site-packages (from streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (1.8.2)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in ./miniconda3/lib/python3.10/site-packages (from streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (13.7.1)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in ./miniconda3/lib/python3.10/site-packages (from streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (0.10.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in ./miniconda3/lib/python3.10/site-packages (from streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (3.1.43)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in ./miniconda3/lib/python3.10/site-packages (from streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (6.4.1)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in ./miniconda3/lib/python3.10/site-packages (from streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (0.9.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./miniconda3/lib/python3.10/site-packages (from streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (8.1.7)\n",
      "Requirement already satisfied: watchdog<5,>=2.1.5 in ./miniconda3/lib/python3.10/site-packages (from streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (4.0.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in ./miniconda3/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (4.22.0)\n",
      "Requirement already satisfied: toolz in ./miniconda3/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (0.12.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./miniconda3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (1.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./miniconda3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./miniconda3/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (3.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./miniconda3/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (4.0.11)\n",
      "Requirement already satisfied: httpcore==1.* in ./miniconda3/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (1.0.5)\n",
      "Requirement already satisfied: certifi in ./miniconda3/lib/python3.10/site-packages (from httpx>=0.24.1->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (2022.12.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./miniconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.14.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./miniconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (1.2.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./miniconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (1.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in ./miniconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./miniconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./miniconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./miniconda3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (4.53.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./miniconda3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./miniconda3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./miniconda3/lib/python3.10/site-packages (from pydantic>=2.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (2.20.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./miniconda3/lib/python3.10/site-packages (from pydantic>=2.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/lib/python3.10/site-packages (from requests->transformers==4.30.2->-r /root/ChatGLM2-6B-main/requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./miniconda3/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./miniconda3/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (2.18.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./miniconda3/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (1.5.4)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in ./miniconda3/lib/python3.10/site-packages (from fastapi->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (2.2.0)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in ./miniconda3/lib/python3.10/site-packages (from fastapi->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.0.4)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in ./miniconda3/lib/python3.10/site-packages (from sympy->torch>=2.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 4)) (1.3.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in ./miniconda3/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (2.6.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./miniconda3/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (5.0.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./miniconda3/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./miniconda3/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (0.18.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./miniconda3/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (2023.12.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./miniconda3/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (23.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./miniconda3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=1.24.0->-r /root/ChatGLM2-6B-main/requirements.txt (line 10)) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./miniconda3/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: httptools>=0.5.0 in ./miniconda3/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./miniconda3/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.22.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./miniconda3/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio->-r /root/ChatGLM2-6B-main/requirements.txt (line 5)) (0.19.0)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.27.1\n",
      "    Uninstalling transformers-4.27.1:\n",
      "      Successfully uninstalled transformers-4.27.1\n",
      "Successfully installed transformers-4.30.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r /root/ChatGLM2-6B-main/requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d7bcc10-36b2-4583-93f2-487f336e5cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Requirement already satisfied: rouge_chinese in ./miniconda3/lib/python3.10/site-packages (1.0.3)\n",
      "Requirement already satisfied: nltk in ./miniconda3/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: jieba in ./miniconda3/lib/python3.10/site-packages (0.42.1)\n",
      "Requirement already satisfied: datasets in ./miniconda3/lib/python3.10/site-packages (2.20.0)\n",
      "Requirement already satisfied: six in ./miniconda3/lib/python3.10/site-packages (from rouge_chinese) (1.16.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./miniconda3/lib/python3.10/site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in ./miniconda3/lib/python3.10/site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: click in ./miniconda3/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./miniconda3/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./miniconda3/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./miniconda3/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./miniconda3/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: packaging in ./miniconda3/lib/python3.10/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in ./miniconda3/lib/python3.10/site-packages (from datasets) (2024.5.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./miniconda3/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./miniconda3/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./miniconda3/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: xxhash in ./miniconda3/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./miniconda3/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in ./miniconda3/lib/python3.10/site-packages (from datasets) (0.24.5)\n",
      "Requirement already satisfied: filelock in ./miniconda3/lib/python3.10/site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: aiohttp in ./miniconda3/lib/python3.10/site-packages (from datasets) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./miniconda3/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (2.3.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./miniconda3/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniconda3/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./miniconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./miniconda3/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./miniconda3/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./miniconda3/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install rouge_chinese nltk jieba datasets -i https://pypi.tuna.tsinghua.edu.cn/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1436996-3d6c-4a06-8417-a8363dbdbeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple/\n",
      "Collecting transformers==4.27.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/6d/9b/2f536f9e73390209e0b27b74691355dac494b7ec8154f3012fdc6debbae7/transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /root/miniconda3/lib/python3.10/site-packages (from transformers==4.27.1) (0.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /root/miniconda3/lib/python3.10/site-packages (from transformers==4.27.1) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.10/site-packages (from transformers==4.27.1) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/lib/python3.10/site-packages (from transformers==4.27.1) (2024.7.24)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/miniconda3/lib/python3.10/site-packages (from transformers==4.27.1) (6.0.1)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.10/site-packages (from transformers==4.27.1) (3.14.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/miniconda3/lib/python3.10/site-packages (from transformers==4.27.1) (4.66.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.10/site-packages (from transformers==4.27.1) (24.1)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.10/site-packages (from transformers==4.27.1) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.1) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.1) (2024.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers==4.27.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers==4.27.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers==4.27.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.10/site-packages (from requests->transformers==4.27.1) (2022.12.7)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.30.2\n",
      "    Uninstalling transformers-4.30.2:\n",
      "      Successfully uninstalled transformers-4.30.2\n",
      "Successfully installed transformers-4.27.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.27.1 -i https://pypi.tuna.tsinghua.edu.cn/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a46fa8d1-1be4-4135-929d-8e083735e41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ChatGLM2-6B-main/ptuning\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf50423-e2ad-4b9e-8ddc-6c348f6bebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a02ca1ac-c109-4b7e-9e64-b41a85ab07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"ChatGLM2-6B-main/ptuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db75ded9-deb9-4b4c-b6b8-ddd114910fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ChatGLM2-6B-main/ptuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ChatGLM2-6B-main/ptuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a9edc97-3efb-42e3-80fd-7230159d765c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-02 13:25:52,722] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.\n",
      "08/02/2024 13:25:56 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False\n",
      "08/02/2024 13:25:56 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=None,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=16,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.02,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=output/adgen-chatglm2-6b-pt-128-2e-2/runs/Aug02_13-25-56_autodl-container-c13b4eab82-4a85c214,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=output/adgen-chatglm2-6b-pt-128-2e-2,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=1,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=output/adgen-chatglm2-6b-pt-128-2e-2,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=100,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "/root/miniconda3/lib/python3.10/site-packages/datasets/load.py:2554: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:667] 2024-08-02 13:25:57,040 >> loading configuration file THUDM/chatglm2-6b/config.json\n",
      "[INFO|configuration_utils.py:667] 2024-08-02 13:25:57,045 >> loading configuration file THUDM/chatglm2-6b/config.json\n",
      "[INFO|configuration_utils.py:725] 2024-08-02 13:25:57,048 >> Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm2-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 32768,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1821] 2024-08-02 13:25:57,052 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:1821] 2024-08-02 13:25:57,052 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:1821] 2024-08-02 13:25:57,052 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1821] 2024-08-02 13:25:57,052 >> loading file tokenizer_config.json\n",
      "[INFO|modeling_utils.py:2575] 2024-08-02 13:25:57,210 >> loading weights file THUDM/chatglm2-6b/pytorch_model.bin.index.json\n",
      "[INFO|configuration_utils.py:577] 2024-08-02 13:25:57,211 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.30.2\"\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:10<00:00,  1.51s/it]\n",
      "[INFO|modeling_utils.py:3295] 2024-08-02 13:26:07,904 >> All model checkpoint weights were used when initializing ChatGLMForConditionalGeneration.\n",
      "\n",
      "[WARNING|modeling_utils.py:3297] 2024-08-02 13:26:07,904 >> Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at THUDM/chatglm2-6b and are newly initialized: ['transformer.prefix_encoder.embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[INFO|modeling_utils.py:2927] 2024-08-02 13:26:07,906 >> Generation config file not found, using a generation config created from the model config.\n",
      "Quantized to 4 bit\n",
      "Running tokenizer on train dataset (num_proc=10): 100%|█| 114599/114599 [00:09<0\n",
      "input_ids [64790, 64792, 790, 30951, 517, 30910, 30939, 30996, 13, 13, 54761, 31211, 33467, 31010, 56532, 30998, 55090, 54888, 31010, 40833, 30998, 32799, 31010, 40589, 30998, 37505, 31010, 37216, 30998, 56532, 54888, 31010, 56529, 56158, 56532, 13, 13, 55437, 31211, 30910, 40833, 54530, 56529, 56158, 56532, 54551, 33808, 32041, 55360, 55486, 32138, 31123, 32943, 33481, 54880, 31664, 46565, 54799, 31155, 33051, 54591, 55432, 33481, 31123, 55622, 32904, 55432, 54557, 56158, 54625, 30943, 55055, 35590, 40833, 54530, 56532, 56158, 31123, 48466, 57148, 55343, 54603, 49355, 55674, 31155, 51605, 55119, 54642, 31799, 54535, 57036, 55625, 31123, 46839, 55113, 56089, 33894, 55778, 31902, 55017, 54706, 56382, 56382, 59230, 31155, 54712, 54882, 31726, 31917, 31735, 45032, 31123, 54656, 54772, 46539, 34481, 54706, 43084, 31155, 46799, 37216, 55351, 55733, 55351, 54600, 54530, 31123, 40589, 58521, 54533, 31155, 33692, 57004, 34678, 54530, 31123, 54619, 44722, 32754, 54626, 33169, 48084, 33149, 54955, 55342, 56842, 31155, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "inputs [Round 1]\n",
      "\n",
      "问：类型#裤*版型#宽松*风格#性感*图案#线条*裤型#阔腿裤\n",
      "\n",
      "答： 宽松的阔腿裤这两年真的吸粉不少，明星时尚达人的心头爱。毕竟好穿时尚，谁都能穿出腿长2米的效果宽松的裤腿，当然是遮肉小能手啊。上身随性自然不拘束，面料亲肤舒适贴身体验感棒棒哒。系带部分增加设计看点，还让单品的设计感更强。腿部线条若隐若现的，性感撩人。颜色敲温柔的，与裤子本身所呈现的风格有点反差萌。\n",
      "label_ids [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 30910, 40833, 54530, 56529, 56158, 56532, 54551, 33808, 32041, 55360, 55486, 32138, 31123, 32943, 33481, 54880, 31664, 46565, 54799, 31155, 33051, 54591, 55432, 33481, 31123, 55622, 32904, 55432, 54557, 56158, 54625, 30943, 55055, 35590, 40833, 54530, 56532, 56158, 31123, 48466, 57148, 55343, 54603, 49355, 55674, 31155, 51605, 55119, 54642, 31799, 54535, 57036, 55625, 31123, 46839, 55113, 56089, 33894, 55778, 31902, 55017, 54706, 56382, 56382, 59230, 31155, 54712, 54882, 31726, 31917, 31735, 45032, 31123, 54656, 54772, 46539, 34481, 54706, 43084, 31155, 46799, 37216, 55351, 55733, 55351, 54600, 54530, 31123, 40589, 58521, 54533, 31155, 33692, 57004, 34678, 54530, 31123, 54619, 44722, 32754, 54626, 33169, 48084, 33149, 54955, 55342, 56842, 31155, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "labels 宽松的阔腿裤这两年真的吸粉不少，明星时尚达人的心头爱。毕竟好穿时尚，谁都能穿出腿长2米的效果宽松的裤腿，当然是遮肉小能手啊。上身随性自然不拘束，面料亲肤舒适贴身体验感棒棒哒。系带部分增加设计看点，还让单品的设计感更强。腿部线条若隐若现的，性感撩人。颜色敲温柔的，与裤子本身所呈现的风格有点反差萌。\n",
      "[INFO|trainer.py:577] 2024-08-02 13:26:24,456 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "/root/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1786] 2024-08-02 13:26:25,113 >> ***** Running training *****\n",
      "[INFO|trainer.py:1787] 2024-08-02 13:26:25,113 >>   Num examples = 114,599\n",
      "[INFO|trainer.py:1788] 2024-08-02 13:26:25,114 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1789] 2024-08-02 13:26:25,114 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:1790] 2024-08-02 13:26:25,114 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1791] 2024-08-02 13:26:25,114 >>   Gradient Accumulation steps = 16\n",
      "[INFO|trainer.py:1792] 2024-08-02 13:26:25,114 >>   Total optimization steps = 1,000\n",
      "[INFO|trainer.py:1793] 2024-08-02 13:26:25,117 >>   Number of trainable parameters = 1,835,008\n",
      "  0%|                                                  | 0/1000 [00:00<?, ?it/s]08/02/2024 13:26:25 - WARNING - transformers_modules.chatglm2-6b.modeling_chatglm - `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/root/miniconda3/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "{'loss': 4.7135, 'learning_rate': 0.0198, 'epoch': 0.0}                         \n",
      "{'loss': 4.0018, 'learning_rate': 0.0196, 'epoch': 0.0}                         \n",
      "{'loss': 3.9378, 'learning_rate': 0.0194, 'epoch': 0.0}                         \n",
      "{'loss': 3.9315, 'learning_rate': 0.0192, 'epoch': 0.01}                        \n",
      "{'loss': 3.8914, 'learning_rate': 0.019, 'epoch': 0.01}                         \n",
      "{'loss': 3.8696, 'learning_rate': 0.0188, 'epoch': 0.01}                        \n",
      "{'loss': 3.8345, 'learning_rate': 0.018600000000000002, 'epoch': 0.01}          \n",
      "{'loss': 3.7796, 'learning_rate': 0.0184, 'epoch': 0.01}                        \n",
      "  8%|███▎                                     | 82/1000 [04:05<45:39,  2.98s/it]^C\n",
      "[2024-08-02 13:30:30,526] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGINT death signal, shutting down workers\n",
      "[2024-08-02 13:30:30,526] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 5450 closing signal SIGINT\n",
      "\n",
      "  8%|███▎                                     | 82/1000 [04:05<45:48,  2.99s/it]\n"
     ]
    }
   ],
   "source": [
    "!bash train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51bffaca-995d-4af5-a36a-1d830cc44819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb7979b9b674a9a9a22fa2aaf6c89fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at THUDM/chatglm2-6b and are newly initialized: ['transformer.prefix_encoder.embedding.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "CHECKPOINT_PATH = \"output/adgen-chatglm2-6b-pt-128-2e-2/checkpoint-100\"\n",
    "# 载入Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT_PATH, trust_remote_code=True)\n",
    "config = AutoConfig.from_pretrained(CHECKPOINT_PATH, trust_remote_code=True, pre_seq_len=128)\n",
    "model = AutoModel.from_pretrained(\"THUDM/chatglm2-6b\", config=config, trust_remote_code=True)\n",
    "prefix_state_dict = torch.load(os.path.join(CHECKPOINT_PATH, \"pytorch_model.bin\"))\n",
    "new_prefix_state_dict = {}\n",
    "for k, v in prefix_state_dict.items():\n",
    "    if k.startswith(\"transformer.prefix_encoder.\"):\n",
    "        new_prefix_state_dict[k[len(\"transformer.prefix_encoder.\"):]] = v\n",
    "model.transformer.prefix_encoder.load_state_dict(new_prefix_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94362562-fed8-4fe2-8620-9c48d522a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out the following line if you don't use quantization\n",
    "# model = model.quantize(4)\n",
    "model = model.cuda()\n",
    "model = model.eval()\n",
    "\n",
    "response, history = model.chat(tokenizer, \"你好\", history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08e1de73-c8d0-46a4-bb9d-29f6255a0dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sear烫裤的设计十分时尚，能够轻松展现女性腿部线条，同时也能展现女性腿部线条的修长感。裤脚的设计也做了 \"<UNK><UNK>\"设计，让裤脚更加修长有型，时尚又个性。'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
